<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Hongbin Liu</title>
  <meta name="google-site-verification" content="UsZrzKAoQgyGMtkUf78O9G3HH19rGgnlLmc-qHUfWRU" />
  <meta name="author" content="Hongbin Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center; font-size: 42px;">
                <name style="font-size:32px">Hongbin Liu</name></br>
                <span style="color: grey; font-size: 18px;">{first_name}{last_name}@google.com</span>
              </p>
              <p style="text-align:justify; font" >
                Hi! I am a Ph.D. student at<a href="https://duke.edu/"> Duke University</a>, where I am fortunate to be supervised by <a href="https://people.duke.edu/~zg70/"> Prof. Neil Gong</a>. My research focuses on security and safety of generative AI, especially multimodal large language models. Priorly, I earned a B.Eng. from the <a href="https://en.ustc.edu.cn/"> University of Science and Technology of China</a> in 2020.
                I worked with <a href="http://www.tongzhang-ml.org/">  Prof. Tong Zhang</a> at HKUST in Summer 2019.
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/img_230729.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/img_230729.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
      
        <script>
          const textSections = [
          {
            element: document.querySelector('p:nth-child(2)'),
            text: ["Hi! I am a Research Scientist at <a href='https://deepmind.google/'>Google DeepMind</a>, where I contribute to <a href='https://gemini.google.com/'>Gemini</a>. I received my Ph.D. from <a href='https://duke.edu/'>Duke University</a> in 2025, advised by <a href='https://people.duke.edu/~zg70/'>Prof. Neil Gong</a>.<br><br>\
            My research and experience span the life cycle of LLMs - from pre-training and post-training to evaluation. My recent work focuses on empowering LLMs with advanced multimodal reasoning, richer contextual signals, and stronger security and safety.<br><br>\
            Earlier, I earned a B.Eng. from the <a href='https://en.ustc.edu.cn/'>University of Science and Technology of China</a> in 2020. I was also fortunate to work with <a href='http://www.tongzhang-ml.org/'>Prof. Tong Zhang</a> in Summer 2019."]
          }
        ];
      
          function typeTextSequentially(index) {
            if (index < textSections.length) {
              const section = textSections[index];
              typeText(section.element, section.text, () => {
                setTimeout(() => {
                  typeTextSequentially(index + 1);
                }, 200); // Delay between sections
              });
            }
          }
      
          function typeText(element, textArray, onComplete, index = 0, position = 0) {
            if (index < textArray.length) {
              const currentText = textArray[index];
              if (position < currentText.length) {
                element.innerHTML = currentText.substring(0, position + 1);
                setTimeout(() => {
                  typeText(element, textArray, onComplete, index, position + 1);
                }, 20); // Adjust the typing speed here
              } else {
                onComplete();
              }
            }
          }
      
          typeTextSequentially(0);
      
          document.querySelectorAll('p').forEach(p => {
            p.addEventListener('click', function(event) {
              if (event.target.tagName === 'A') {
                const linkHref = event.target.getAttribute('href');
                if (linkHref) {
                  window.location.href = linkHref;
                }
              }
            });
          });
        </script>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications  (*Equal contributions)  </heading> 
              <p> 2025 </p>
              <ul>
                <li>
                  <a href="https://arxiv.org/abs/2507.06261">Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities
                  </a><br>
                  <strong>Gemini Team, Google</strong>. <br>
                  <em>Technical Report.</em>
                </li><br>
                <li>
                  <a href="https://arxiv.org/abs/2406.06979">Differentially Private Parameter-Efficient Fine-tuning for Large ASR Models
                  </a><br>
                  <strong>Hongbin Liu</strong>, Lun Wang, Om Thakkar, Abhradeep Thakurta, Arun Narayanan. <br>
                  <em>Conference of the International Speech Communication Association (Interspeech).</em>
                </li><br>
                <li>
                  <a href="https://arxiv.org/abs/2410.14827">Enhancing Prompt Injection Attacks to LLMs via Poisoning Alignment
                  </a><br>
                  Zedian Shao*, <strong>Hongbin Liu*</strong>, Jaden Mu, Neil Zhenqiang Gong. <br>
                  <em> ACM Workshop on Artificial Intelligence and Security (AISec). </em>
              </li><br>
              </ul>
              <p> 2024 </p>
              <ul>
              <li>
                <a href="https://arxiv.org/abs/2406.06979">AudioMarkBench: Benchmarking Robustness of Audio Watermarking
                </a><br>
                <strong>Hongbin Liu*</strong>, Moyang Guo*, Zhengyuan Jiang, Lun Wang, Neil Zhenqiang Gong. <br>
                <em>Datasets and Benchmarks Track in Conference on Neural Information Processing Systems (NeurIPS).</em>
              </li><br>
              <li>
                <a href="https://www.usenix.org/system/files/sec24summer-prepub-832-liu-hongbin.pdf">Mudjacking: Patching Backdoor Vulnerabilities in Foundation Models
                </a><br>
                <strong>Hongbin Liu</strong>, Michael K Reiter, Neil Zhenqiang Gong.<br>
                <em>USENIX Security Symposium.</em>
              </li><br>
              <li>
                <a href="https://arxiv.org/abs/2402.14683">Visual Hallucinations of Multi-modal Large Language Models
                </a><br>
                Wen Huang*, <strong>Hongbin Liu*</strong>, Minxin Guo, Neil Zhenqiang Gong. <br>
                <em>Findings of the Association for Computational Linguistics (ACL)</em>
              </li><br>
              <li>
                <a href="https://www.trust-ai.world/">Differentially Private Parameter-Efficient Fine-tuning for Large ASR Models
                </a><br>
                <strong>Hongbin Liu</strong>, Lun Wang, Om Thakkar, Abhradeep Guha Thakurta, and Arun Narayanan.<br>
                <em>DLSP @ IEEE Symposium on Security and Privacy.</em>
              </li><br>
              <li>
                <a href="https://arxiv.org/abs/2402.14683">Pre-trained Encoders in Self-Supervised Learning Improve Secure and Privacy-preserving Supervised Learning
                </a><br>
                <strong>Hongbin Liu*</strong>, Wenjie Qu*, Jinyuan Jia, Neil Zhenqiang Gong. <br>
                <em>Security Architectures for Generative Artificial Intelligence (SAGAI) @ IEEE Symposium on Security and Privacy.</em>
            </li><br>
              <li>
                <a href="https://arxiv.org/abs/2211.08229">CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive Learning
                </a><br>
                Jinghuai Zhang, <strong>Hongbin Liu</strong>, Jinyuan Jia, Neil Zhenqiang Gong.<br>
                <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR).</em>
            </li><br>
              <li>
                <a href="https://link.springer.com/chapter/10.1007/978-3-031-42637-7_8">10 Security and Privacy Problems in Large Foundation Models
                </a><br>
                Jinyuan Jia, <strong>Hongbin Liu</strong>, Neil Zhenqiang Gong.<br>
                <em>Book Chapter @ AI Embedded Assurance for Cyber Systems.</em>
            </li><br>
              </ul>
              <p> 2023 </p>
              <ul>
                <li>
                  <a href="https://www.sciencedirect.com/science/article/pii/S0167404823000883">Generation-based fuzzing? Donâ€™t build a new generator, reuse!
                  </a><br>
                  Chengbin Pang, <strong>Hongbin Liu</strong>, Yifan Wang, Neil Zhenqiang Gong, Bing Mao, and Jun Xu.<br>
                  <em>Computers & Security</em>
              </li><br>
                <li>
                  <a href="https://arxiv.org/pdf/2303.01959.pdf">PointCert: Point Cloud Classification with Deterministic Certified Robustness Guarantees
                  </a><br>
                  Jinghuai Zhang, Jinyuan Jia, <strong>Hongbin Liu</strong>, and Neil Zhenqiang Gong.<br>
                  <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>
              </li><br>
              </ul>
                <p> 2022 </p>
                <ul>
                  <li>
                    <a href="https://arxiv.org/pdf/2205.06401.pdf">PoisonedEncoder: Poisoning the Unlabeled Pre-training Data in Contrastive Learning
                    </a><br>
                    <strong>Hongbin Liu</strong>, Jinyuan Jia, and Neil Zhenqiang Gong.<br> 
                    <em>USENIX Security Symposium.</em>
                  </li><br>
                  <li>
                    <a href="https://arxiv.org/pdf/2207.12535.pdf">Semi-Leak: Membership Inference Attacks Against Semi-supervised Learning
                    </a><br>
                    Xinlei He, <strong>Hongbin Liu</strong>, Neil Zhenqiang Gong, and Yang Zhang.<br> 
                    <em>European Conference on Computer Vision (ECCV).</em>
                  </li><br>
                  <li>
                    <a href="https://arxiv.org/pdf/2201.05889.pdf">StolenEncoder: Stealing Pre-trained Encoders in Self-supervised Learning
                    </a><br>
                    Yupei Liu, Jinyuan Jia, <strong>Hongbin Liu</strong>, Neil Zhenqiang Gong.<br> 
                    <em>ACM Conference on Computer and Communications Security (CCS).</em>
                  </li><br>
                  <li>
                    <a href="https://arxiv.org/pdf/2011.07633.pdf">Almost Tight L0-norm Certified Robustness of Top-k Predictions against Adversarial Perturbations
                    </a><br>
                    Jinyuan Jia, Binghui Wang, Xiaoyu Cao, <strong>Hongbin Liu</strong> and Neil Zhenqiang Gong.<br> 
                    <em>International Conference on Learning Representations (ICLR).</em>
                  </li><br>
                </ul>
                  <p> 2021 </p>
                  <ul>
                      <li>
                          <a href="https://arxiv.org/pdf/2108.11023.pdf">EncoderMI: Membership Inference against Pre-trained Encoders in Contrastive Learning
                          </a><br>
                          <strong>Hongbin Liu</strong>*, Jinyuan Jia*, Wenjie Qu and Neil Zhenqiang Gong. <br> 
                          <em>ACM Conference on Computer and Communications Security (CCS)</em>
                      </li><br>
                      <li>
                          <a href="https://arxiv.org/pdf/2103.03046.pdf">PointGuard: Provably Robust 3D Point Cloud Classification
                          </a><br>
                          <strong>Hongbin Liu</strong>*, Jinyuan Jia* and Neil Zhenqiang Gong. <br>
                          <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>
                      </li><br>
                      <li>
                          <a href="https://arxiv.org/pdf/2008.09845.pdf">On the Intrinsic Differential Privacy of Bagging
                          </a><br>
                          <strong>Hongbin Liu</strong>, Jinyuan Jia and Neil Zhenqiang Gong.<br>
                          <em>International Joint Conference on Artificial Intelligence (IJCAI)</em>
                      </li><br>
                  </ul>
            </td>
            </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Preprints (*Equal contributions) </heading> 
            <p> 2025 </p>
            <li>
              <a href="https://arxiv.org/abs/2410.11242">Automatically Generating Visual Hallucination Test Cases for Multimodal Large Language Models
              </a><br>
              Zhongye Liu*, <strong>Hongbin Liu*</strong>, Yuepeng Hu, Zedian Shao, Neil Zhenqiang Gong.<br>
          </li><br>
            <li>
              <a href="https://arxiv.org/abs/2410.06572">Can DeepFake Speech be Reliably Detected?
              </a><br>
              <strong>Hongbin Liu*</strong>, Youzheng Chen, Arun Narayanan, Athula Balachandran, Pedro J. Moreno, Lun Wang*. <br>
          </li><br>
            <li>
              <a href="https://arxiv.org/abs/2407.09050">Refusing Safe Prompts for Multi-modal Large Language Models
              </a><br>
              Zedian Shao*, <strong>Hongbin Liu*</strong>, Yuepeng Hu, Neil Zhenqiang Gong. <br>
          </li><br>
          <li>
            <a href="https://arxiv.org/abs/2407.07221">Tracing Back the Malicious Clients in Poisoning Attacks to Federated Learning
            </a><br>
            Yuqi Jia, Minghong Fang, <strong>Hongbin Liu</strong>, Jinghuai Zhang, Neil Zhenqiang Gong. <br>
        </li><br>
                </td>
              </tr>
          </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading style="font-size: 22px; font-weight: bold;">Experiences</heading> 
              <p> May 2024 - Aug. 2024: Research Intern, <a href="https://ai.google/">Google AI</a>.</p>
              <p> June 2023 - Jan. 2024: Student Researcher, <a href="https://ai.google/">Google AI</a>.</p>
              <p> Jan. 2021 - Apr. 2021: Research Intern, <a href="https://www.alibabagroup.com/en-US">Alibaba Group</a>.</p>
              <p> Jul. 2019 - Sep. 2019: Research Intern, <a href="https://hkust.edu.hk/">HKUST</a>.</p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading style="font-size: 22px; font-weight: bold;">Academic Activities</heading> 
              <p> Conference Reviewer: ECCV 2024, ACCV 2024, <a href="https://iccv2023.thecvf.com/"> ICCV</a> 2023.</p>
              <p> Journal Reviewer:<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=10206"> T-IFS</onbehalfof></a> 2023.</p>
            </td>
          </tr>
        </tbody></table>

          <footer class="footer">
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tr>
                    <td width=30%>
                        <br>
                        <p align="left">
                            <font size="2">
                                Updated March 2025.
                            </font>
                        </p>
                    </td>

                    <td width=40% align="center" hidden="hidden">
                      <a href="https://clustrmaps.com/site/1bl80"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=p50vKcM-nrOZmNqIPVxMBYv8gETkGPaJxWjM23aTZQg&cl=ffffff" /></a>
                    </td>
                    <td width=30%>
                        <br>
                        <p align="right">
                            <font size="2">
                                Thanks <a href="https://jonbarron.info/">Jon Barron</a> for website template.
                            </font>
                        </p>
                    </td>
                </tr>
            </table>
        </footer>

      </td>
    </tr>
  </table>
</body>

</html>
